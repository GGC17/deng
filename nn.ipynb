{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arbitrary-infection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T22:33:36.164833Z",
     "start_time": "2021-06-22T22:33:36.157832Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "right-instrument",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T20:56:31.421635Z",
     "start_time": "2021-06-22T20:56:31.343141Z"
    }
   },
   "outputs": [],
   "source": [
    "rooth_path = 'data/'\n",
    "deng_sj = pd.read_csv(rooth_path + 'deng_sj.csv')\n",
    "deng_iq = pd.read_csv(rooth_path + 'deng_iq.csv')\n",
    "test_sj = pd.read_csv(rooth_path + 'test_sj.csv')\n",
    "test_iq = pd.read_csv(rooth_path + 'test_iq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_celsius(df):\n",
    "    \n",
    "    k = 273.15\n",
    "    \n",
    "    # convert to celsius\n",
    "    df['reanalysis_air_temp_k'] -= k\n",
    "    df['reanalysis_avg_temp_k'] -= k\n",
    "    df['reanalysis_dew_point_temp_k'] -= k\n",
    "    df['reanalysis_max_air_temp_k'] -= k\n",
    "    df['reanalysis_min_air_temp_k'] -= k\n",
    "    \n",
    "    # change features names\n",
    "    col = df.columns\n",
    "    col = col.str.replace('temp_k', 'temp_c')\n",
    "    df.columns = col.str.replace('tdtr_k', 'tdtr_c')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj = convert_celsius(deng_sj)\n",
    "deng_iq = convert_celsius(deng_iq)\n",
    "test_sj = convert_celsius(test_sj)\n",
    "test_iq = convert_celsius(test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ndvi(df):\n",
    "    \n",
    "    df['ndvi_mean'] = df[df.columns[3:7]].mean(axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj = mean_ndvi(deng_sj)\n",
    "deng_iq = mean_ndvi(deng_iq)\n",
    "test_sj = mean_ndvi(test_sj)\n",
    "test_iq = mean_ndvi(test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, columns):\n",
    "    \n",
    "    df.drop(columns = columns, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj = feature_selection(deng_sj, ['reanalysis_air_temp_c', 'reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_c'])\n",
    "deng_iq = feature_selection(deng_iq, ['reanalysis_avg_temp_c', 'reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_c'])\n",
    "test_sj = feature_selection(test_sj, ['reanalysis_air_temp_c', 'reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_c'])\n",
    "test_iq = feature_selection(test_iq, ['reanalysis_avg_temp_c', 'reanalysis_sat_precip_amt_mm', 'reanalysis_dew_point_temp_c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_feat(df, df_test, roll_win_size, city):\n",
    "    \n",
    "    # save total cases in a dataframe\n",
    "    total_cases = df[['city', 'year', 'weekofyear', 'total_cases']]\n",
    "    \n",
    "    df.drop(columns=['total_cases'], inplace=True)\n",
    "    \n",
    "    total_df = pd.concat([df, df_test], axis=0)\n",
    "    \n",
    "    cols = total_df.columns[4:] #Features columns excluding week_start_date, city and weekofyear\n",
    "    \n",
    "    for col in cols:\n",
    "        total_df[col + '_sum']  = total_df[col].rolling(roll_win_size).sum()\n",
    "        total_df[col + '_av'] = total_df[col].rolling(roll_win_size).mean()\n",
    "        total_df[col + '_var']  = total_df[col].rolling(roll_win_size).var()\n",
    "        \n",
    "    # Split train-test again\n",
    "    \n",
    "    if city == 'San Juan':\n",
    "        df_ = total_df[total_df.week_start_date < '2008-04-29']\n",
    "        df_test = total_df[total_df.week_start_date >= '2008-04-29']\n",
    "    \n",
    "    if city == 'Iquitos':\n",
    "        df_ = total_df[total_df.week_start_date < '2010-07-02']\n",
    "        df_test = total_df[total_df.week_start_date >= '2010-07-02']\n",
    "    \n",
    "    df_ = df_.merge(total_cases, on=['city', 'year', 'weekofyear'])\n",
    "      \n",
    "    df_.dropna(axis=0, inplace=True) #trim rows with null values of rolling features\n",
    "    \n",
    "    return df_, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj_train, test_sj = rolling_feat(deng_sj, test_sj, 4, 'San Juan')\n",
    "deng_iq_train, test_iq = rolling_feat(deng_iq, test_iq, 4, 'Iquitos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_quarters(df):\n",
    "    \n",
    "    df['week_start_date'] = pd.to_datetime(df.week_start_date)\n",
    "    df['quarter'] = df['week_start_date'].dt.quarter\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['quarter'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj_train = enc_quarters(deng_sj_train)\n",
    "deng_iq_train = enc_quarters(deng_iq_train)\n",
    "test_sj = enc_quarters(test_sj)\n",
    "test_iq = enc_quarters(test_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    \n",
    "    split = df.shape[0] - df.shape[0]*0.1 # Split with train 90% and validation 10%\n",
    "    \n",
    "    df_train = df[df.index < split]\n",
    "    df_val = df[df.index >= split]\n",
    "    \n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "deng_sj_train, deng_sj_val = split_df(deng_sj_train) #SJ split data in train-validation\n",
    "deng_iq_train, deng_iq_val = split_df(deng_iq_train) #IQ split data in train-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-alexander",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-madness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-black",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYERS\n",
    "def init_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.LSTM(20, return_sequences=True, activation='tanh'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.LSTM(10, return_sequences=True, activation='tanh'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.LSTM(10, activation='tanh'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(5, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', \n",
    "                  optimizer='rmsprop', \n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "            validation_split=0.15,\n",
    "            epochs=1000, \n",
    "            batch_size=16,\n",
    "            callbacks=[es])\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_mae(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['mae'])\n",
    "    plt.plot(history.history['val_mae'])\n",
    "    plt.title('Model Mean Absolute Error')\n",
    "    plt.ylabel('Mean Absolute Error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
